{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of extractive structures results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The snakeviz extension is already loaded. To reload it, use:\n",
      "  %reload_ext snakeviz\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%load_ext snakeviz\n",
    "%autoreload 2\n",
    "# Add the top level of the directory to the python path, so we can import the scripts\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "from shared_ml.utils import get_root_of_git_repo\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from transformers.generation.utils import GenerationConfig, GenerateBeamDecoderOnlyOutput\n",
    "from shared_ml.utils import default_function_args_to_cache_id, hash_str\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "from typing import Any\n",
    "from termcolor import colored\n",
    "repo_root = get_root_of_git_repo()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, cast\n",
    "import seaborn as sns\n",
    "import json\n",
    "from oocr_influence.cli.train_extractive import TrainingArgs\n",
    "from oocr_influence.cli.run_influence import InfluenceArgs\n",
    "from oocr_influence.cli.train_extractive import TrainingArgs\n",
    "from oocr_influence.cli.run_influence import InfluenceArgs\n",
    "from dataclasses import dataclass\n",
    "from datasets import DatasetDict\n",
    "from shared_ml.logging import LogState, load_log_from_wandb, paths_or_wandb_to_logs\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import TypeVar\n",
    "from numpy.typing import NDArray\n",
    "from shared_ml.utils import cache_function_outputs\n",
    "from itertools import chain, groupby\n",
    "import numpy.typing as npt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "if repo_root not in sys.path:\\\n",
    "    sys.path.append(repo_root)\n",
    "# Also chang the CWD to the repo, so we can import items from the various scripts.\n",
    "os.chdir(repo_root)\n",
    "from shared_ml.logging import load_experiment_checkpoint\n",
    "\n",
    "# from examples.mnist.pipeline import get_mnist_dataset, construct_mnist_classifier, add_box_to_mnist_dataset\n",
    "\n",
    "import logging\n",
    "from typing import Literal\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2LMHeadModel, Conv1D\n",
    "from torch import nn\n",
    "from kronfluence.analyzer import Analyzer, prepare_model\n",
    "from datasets import Dataset\n",
    "from kronfluence.arguments import FactorArguments, ScoreArguments\n",
    "from kronfluence.task import Task\n",
    "from kronfluence.utils.common.factor_arguments import all_low_precision_factor_arguments\n",
    "from kronfluence.utils.common.score_arguments import all_low_precision_score_arguments\n",
    "from kronfluence.utils.dataset import DataLoaderKwargs\n",
    "import numpy as np\n",
    "from kronfluence.score import load_pairwise_scores\n",
    "from oocr_influence.cli.run_influence import InfluenceArgs\n",
    "\n",
    "# from examples.mnist.pipeline import get_mnist_dataset, construct_mnist_classifier, add_box_to_mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "(datetime.now() - datetime(datetime.now().year, 1, 1)).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Any, Literal\n",
    "import line_profiler\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "from functools import cache\n",
    "from typing import Generator\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "from shared_ml.utils import cache_function_outputs\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes import Axes\n",
    "import seaborn as sns\n",
    "from termcolor import colored\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import math\n",
    "\n",
    "\n",
    "@cache_function_outputs(cache_dir=Path(\"./analysis/cache_dir/\"), function_args_to_cache_id = lambda x: hashlib.sha256(x[\"input_array\"].tobytes()).hexdigest()[:8]) # type: ignore\n",
    "def rank_influence_scores(input_array: np.ndarray[Any, Any] | torch.Tensor) -> np.ndarray[Any, Any]:\n",
    "    if isinstance(input_array, torch.Tensor):\n",
    "        input_array = input_array.cpu().numpy()\n",
    "    return np.argsort(np.argsort(-input_array, axis=1), axis=1)\n",
    "\n",
    "def get_parent_influence_scores(influence_scores: np.ndarray[Any,np.dtype[Any]] | torch.Tensor, test_dataset: Dataset) -> np.ndarray[Any,np.dtype[Any]]:\n",
    "    if isinstance(influence_scores, torch.Tensor):\n",
    "        influence_scores = influence_scores.cpu().numpy()\n",
    "    parent_idxs: list[int] = test_dataset[\"parent_fact_idx\"]\n",
    "    influence_scores_by_parent = influence_scores[np.arange(len(influence_scores)), parent_idxs]\n",
    "    return influence_scores_by_parent\n",
    "\n",
    "\n",
    "def cache_get_parent_influence_ranks(args: dict[str,Any]) -> str:\n",
    "    train_dataset_fingerprint = args[\"train_dataset\"]._fingerprint\n",
    "    test_dataset_fingerprint = args[\"test_dataset\"]._fingerprint\n",
    "    influence_scores_hash = hashlib.sha256(args[\"influence_scores\"].tobytes()).hexdigest()[:8]\n",
    "    non_parents_instead_of_parents = str(args[\"non_parents_instead_of_parents\"])\n",
    "    return hash_str(f\"{train_dataset_fingerprint}-{test_dataset_fingerprint}-{influence_scores_hash}-{non_parents_instead_of_parents}\")\n",
    "\n",
    "@cache_function_outputs(cache_dir=Path(\"./analysis/cache_dir/\"), function_args_to_cache_id = cache_get_parent_influence_ranks)\n",
    "def get_parent_influence_ranks(influence_scores: NDArray[Any] | torch.Tensor, train_dataset: Dataset, test_dataset: Dataset, non_parents_instead_of_parents : bool = True) -> dict[int,NDArray[Any]]:\n",
    "    \n",
    "    influence_scores_rank = rank_influence_scores(influence_scores)\n",
    "\n",
    "    types = train_dataset[\"type\"]\n",
    "    idxs = train_dataset[\"idx\"]\n",
    "    train_set_parent_idxs = [idx if \"fact\" in t else None for t,idx in zip(types,idxs)]\n",
    "    \n",
    "    parent_idxs_to_train_set_idxs = defaultdict(list)\n",
    "\n",
    "    for train_set_idx, train_set_parent_idx in enumerate(train_set_parent_idxs):\n",
    "        if train_set_parent_idx is not None:\n",
    "            parent_idxs_to_train_set_idxs[train_set_parent_idx].append(train_set_idx)\n",
    "        \n",
    "    if non_parents_instead_of_parents:\n",
    "        # Make it so that you are in the list if you are NOT a parent\n",
    "        all_indices = set(range(len(train_dataset)))\n",
    "        parent_idxs_to_train_set_idxs = {k: list(all_indices - set(v)) for k, v in parent_idxs_to_train_set_idxs.items()}\n",
    "    parent_idxs_to_influence_ranks = {parent_idx: influence_scores_rank[parent_idx,train_set_idxs] for parent_idx,train_set_idxs in parent_idxs_to_train_set_idxs.items()}\n",
    "\n",
    "    return parent_idxs_to_influence_ranks  \n",
    "\n",
    "def plot_histogram_train_subset(influence_scores: NDArray[Any] | torch.Tensor, train_dataset: Dataset, subset_inds: list[int], title: str, xlabel: str, ylabel: str,bin_width: int = 10,max_value: int | None = None, fig: Figure | None = None, ax: Axes | None = None):\n",
    "    if isinstance(influence_scores, torch.Tensor):\n",
    "        influence_scores = influence_scores.to(dtype=torch.float32).cpu().numpy()\n",
    "\n",
    "    influence_ranks = rank_influence_scores(influence_scores)\n",
    "    max_value = max_value or np.max(influence_ranks)\n",
    "    subset_influence_ranks = influence_ranks[:,subset_inds]\n",
    "    if fig is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        ax = fig.gca()\n",
    "    \n",
    "    ax.hist(subset_influence_ranks.flatten(), edgecolor=\"black\", bins=np.arange(0, max_value + 1, bin_width)) # type: ignore\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    # show the figure\n",
    "    fig.show()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_histogram_parent_ranks(influence_scores: NDArray[Any] | torch.Tensor, train_dataset: Dataset, test_dataset: Dataset, title: str, xlabel: str, ylabel: str, max_value: int | None = None, bin_width: int = 10,non_parents_instead_of_parents: bool = \n",
    "                                False,parent_inds: list[int] | None = None):\n",
    "    if isinstance(influence_scores, torch.Tensor):\n",
    "        influence_scores = influence_scores.to(dtype=torch.float32).cpu().numpy()\n",
    "    parent_influence_ranks = get_parent_influence_ranks(influence_scores, train_dataset, test_dataset,non_parents_instead_of_parents)\n",
    "    if parent_inds is not None:\n",
    "        parent_influence_ranks = {k: v for k, v in parent_influence_ranks.items() if k in parent_inds}\n",
    "    parent_influence_ranks = np.array(list(chain(*parent_influence_ranks.values())))\n",
    "    fig, ax = plt.subplots()    \n",
    "    max_value = max_value or np.max(parent_influence_ranks)\n",
    "    ax.hist(parent_influence_ranks.flatten(), edgecolor=\"black\", bins=np.arange(0, max_value + 1, bin_width))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    fig.show()\n",
    "\n",
    "def plot_histogram_parent_ranks_seaborn(\n",
    "    influence_scores: NDArray[Any] | torch.Tensor,\n",
    "    train_dataset: Dataset,\n",
    "    test_dataset: Dataset,\n",
    "    title: str,\n",
    "    xlabel: str,\n",
    "    ylabel: str,\n",
    "    max_value: int | None = None,\n",
    "    bin_width: int = 10,\n",
    "    non_parents_instead_of_parents: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots overlaid histograms for parent influence ranks using Seaborn.\n",
    "\n",
    "    Each row in the calculated parent_influence_ranks array gets its own\n",
    "    histogram overlaid on the same plot.\n",
    "\n",
    "    Args:\n",
    "        influence_scores: A 2D array or tensor of influence scores (e.g., test_instances x train_instances).\n",
    "        train_dataset: The training dataset object.\n",
    "        test_dataset: The test dataset object.\n",
    "        title: The title for the plot.\n",
    "        xlabel: The label for the x-axis.\n",
    "        ylabel: The label for the y-axis.\n",
    "        max_value: The maximum value for the x-axis and bin calculation. If None, determined from data.\n",
    "        bin_width: The width of each histogram bin.\n",
    "        non_parents_instead_of_parents: Flag passed to get_parent_influence_ranks.\n",
    "    \"\"\"\n",
    "    if isinstance(influence_scores, torch.Tensor):\n",
    "        influence_scores_np = influence_scores.to(dtype=torch.float32).cpu().numpy()\n",
    "    else:\n",
    "        influence_scores_np = np.asarray(influence_scores) # Ensure it's a numpy array\n",
    "\n",
    "    # Get the 2D array of ranks (DO NOT FLATTEN here)\n",
    "    parent_influence_ranks_2d = get_parent_influence_ranks(\n",
    "        influence_scores_np, train_dataset, test_dataset, non_parents_instead_of_parents\n",
    "    )\n",
    "\n",
    "    if parent_influence_ranks_2d.size == 0: # type: ignore\n",
    "        print(\"Warning: parent_influence_ranks_2d is empty. Cannot plot histogram.\")\n",
    "        return\n",
    "\n",
    "    # --- Convert data to long-form DataFrame for Seaborn ---\n",
    "    data_for_df = []\n",
    "    for i, ranks_for_row in enumerate(parent_influence_ranks_2d):\n",
    "        for rank in ranks_for_row:\n",
    "            data_for_df.append({'rank': rank, 'row_index': i})\n",
    "            \n",
    "    if not data_for_df:\n",
    "         print(\"Warning: No data found after processing ranks. Cannot plot histogram.\")\n",
    "         return\n",
    "         \n",
    "    df = pd.DataFrame(data_for_df)\n",
    "    # Ensure row_index is treated as a category for distinct colors\n",
    "    df['row_index'] = df['row_index'].astype('category') \n",
    "    # --- ---\n",
    "\n",
    "    # Determine the maximum value for bins if not provided\n",
    "    actual_max_rank = df['rank'].max()\n",
    "    plot_max_value = max_value if max_value is not None else actual_max_rank\n",
    "    \n",
    "    # Define bins carefully to include the max value\n",
    "    bins = np.arange(0, plot_max_value + bin_width, bin_width)\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6)) # Adjust figsize as needed\n",
    "\n",
    "    # Use seaborn histplot\n",
    "    sns.histplot(\n",
    "        data=df,\n",
    "        x='rank',\n",
    "        hue='row_index', # Color histograms by original row index\n",
    "        bins=bins,\n",
    "        binwidth=bin_width if bins is None else None, # Use either bins or binwidth\n",
    "        element=\"step\",  # Use 'step' for better visibility of overlays\n",
    "        # kde=True,       # Uncomment to add Kernel Density Estimate plots\n",
    "        ax=ax,\n",
    "        palette='viridis', # Choose a color palette (optional)\n",
    "        legend=True        # Show legend\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel) # Seaborn might label this 'Count', override if needed\n",
    "\n",
    "    # Optional: Set x-axis limit if max_value was specified\n",
    "    if max_value is not None:\n",
    "        ax.set_xlim(0, max_value)\n",
    "    else:\n",
    "        # Ensure the last bin edge is slightly beyond the max rank if automatically determined\n",
    "         ax.set_xlim(0, plot_max_value + bin_width) \n",
    "\n",
    "\n",
    "    # Improve legend if there are many rows\n",
    "    if len(df['row_index'].unique()) > 10:\n",
    "         ax.legend(title='Row Index', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "         plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend\n",
    "    else:\n",
    "         ax.legend(title='Row Index')\n",
    "         plt.tight_layout()\n",
    "\n",
    "\n",
    "    # Use plt.show() for standard execution environments \n",
    "    # or fig.show() potentially in specific interactive environments\n",
    "    plt.show()\n",
    "\n",
    "def get_mlp_and_attention_groups(module_names: list[str]) -> tuple[list[list[str]], list[list[str]]]:\n",
    "    \n",
    "    layer_match = re.compile(r\"\\.(\\d+)\\.\")\n",
    "    layers = [int(layer_match.search(module_name).group(1)) for module_name in module_names ]\n",
    "    layer_mlp_groups : list[list[str]] = [[] for _ in range(max(layers)+ 1)]\n",
    "    layer_attention_groups : list[list[str]] = [[] for _ in range(max(layers)+ 1)]\n",
    "    \n",
    "    for module_name, layer in zip(module_names, layers):\n",
    "        if \"mlp\" in module_name:\n",
    "            layer_mlp_groups[layer].append(module_name)\n",
    "        elif \"attn\" in module_name:\n",
    "            layer_attention_groups[layer].append(module_name)\n",
    "\n",
    "    return layer_mlp_groups, layer_attention_groups\n",
    "def plot_heatmap_influence_scores_by_layer(influence_scores_by_layer: dict[str, np.ndarray] | dict[str, torch.Tensor], train_dataset: Dataset, test_dataset: Dataset, title: str, xlabel: str, ylabel: str, aggregation_type: Literal[\"sum\", \"abs_sum\",\"ranks_above_median\",\"ranks_below_median\"] = \"sum\"):\n",
    "    if isinstance(next(iter(influence_scores_by_layer.values())), torch.Tensor):\n",
    "        influence_scores_by_layer = {k: v.to(dtype=torch.float32).cpu().numpy() for k, v in influence_scores_by_layer.items()} # type: ignore\n",
    "    parent_idxs = test_dataset[\"parent_fact_idx\"]\n",
    "    \n",
    "    groups_mlp, groups_attention = get_mlp_and_attention_groups(list(influence_scores_by_layer.keys()))\n",
    "     \n",
    "    title = f\"{title} ({aggregation_type})\"\n",
    "        \n",
    "    \n",
    "    if aggregation_type == \"sum\" or aggregation_type == \"abs_sum\":\n",
    "        groups_to_influence = {}\n",
    "        for group_name, group in zip([\"attention\", \"mlp\"], [groups_attention, groups_mlp]):\n",
    "            layer_group_to_influence = defaultdict(float)\n",
    "            for layer_num, layer_group in enumerate(group):\n",
    "                layer_group_influence = 0\n",
    "                for layer_name in layer_group:\n",
    "                    influence_score = influence_scores_by_layer[layer_name]\n",
    "                    influence_score_by_parent = influence_score[np.arange(len(influence_score)), parent_idxs]\n",
    "                    if aggregation_type == \"abs_sum\":\n",
    "                        influence_score_by_parent = np.abs(influence_score_by_parent)\n",
    "                    \n",
    "                    layer_group_influence += np.sum(influence_score_by_parent)\n",
    "                \n",
    "                layer_group_to_influence[f\"{group_name}_{layer_num}\"] = layer_group_influence\n",
    "            \n",
    "            groups_to_influence[group_name] = layer_group_to_influence\n",
    "    elif aggregation_type == \"ranks_below_median\" or aggregation_type == \"ranks_above_median\":\n",
    "        groups_to_influence = {}\n",
    "        for group_name, group in zip([\"attention\", \"mlp\"], [groups_attention, groups_mlp]):\n",
    "            layer_group_to_influence_array = defaultdict(lambda: np.zeros(len(parent_idxs)))\n",
    "            for layer_num, layer_group in enumerate(group):\n",
    "                layer_group_influence_parents  = np.zeros(len(parent_idxs))\n",
    "                for layer_name in layer_group:\n",
    "                    influence_score = influence_scores_by_layer[layer_name]\n",
    "                    influence_score_by_parent = influence_score[np.arange(len(influence_score)), parent_idxs]\n",
    "                    if aggregation_type == \"ranks_below_median\":\n",
    "                        influence_score_by_parent = -influence_score_by_parent\n",
    "                    layer_group_influence_parents += influence_score_by_parent\n",
    "                \n",
    "                layer_group_to_influence_array[f\"{group_name}_{layer_num}\"] = layer_group_influence_parents\n",
    "                \n",
    "                \n",
    "            layer_group_influence_stacked = np.stack(list(layer_group_to_influence_array.values()), axis=0)\n",
    "            \n",
    "            # now, rank the influence scores for each parent, and then subtract the median rank, clipping at 0 from all the ranks\n",
    "            layer_group_influence_stacked_ranks = np.argsort(np.argsort(-layer_group_influence_stacked, axis=0), axis=0)\n",
    "            layer_group_influence_stacked_ranks_above_median = np.clip(layer_group_influence_stacked_ranks - np.median(layer_group_influence_stacked_ranks, axis=0, keepdims=True), 0, None)\n",
    "            layer_group_influence = np.sum(layer_group_influence_stacked_ranks_above_median, axis=1)\n",
    "            layer_group_to_influence = {}\n",
    "            for layer_name, influence in zip(list(layer_group_to_influence_array.keys()), layer_group_influence):\n",
    "                layer_group_to_influence[layer_name] = influence\n",
    "            \n",
    "            groups_to_influence[group_name] = layer_group_to_influence\n",
    "    else:\n",
    "        raise ValueError(f\"Aggregation type {aggregation_type} not recognised\")\n",
    "\n",
    "    # Create a single figure with side-by-side subfigures for attention and mlp\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 10))\n",
    "    \n",
    "    for i, (group_name, layer_group_to_influence) in enumerate(groups_to_influence.items()):\n",
    "        ax = axes[i]\n",
    "        influences_array = np.array(list(layer_group_to_influence.values())).reshape(-1, 1)\n",
    "        # add yticks for each layer name\n",
    "        ax.set_yticks(np.arange(len(layer_group_to_influence)))\n",
    "        sns.heatmap(influences_array[:,::-1], cmap=\"viridis\", ax=ax, yticklabels=list(layer_group_to_influence.keys())[::-1])\n",
    "        ax.set_title(f\"{title} - {group_name.capitalize()}\")\n",
    "        ax.set_xlabel(xlabel)\n",
    "        if i == 0:  # Only add y-label to the first subplot\n",
    "            ax.set_ylabel(ylabel)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "# TODO: Some trickyness about normalising scores by layer\n",
    "def plot_magnitude_across_queries(influence_scores: np.ndarray[Any, Any] | torch.Tensor, train_dataset: Dataset, test_dataset: Dataset, title: str, xlabel: str, ylabel: str, is_per_token: bool):\n",
    "    \n",
    "    magnitudes = np.sum(np.abs(influence_scores), axis=1)\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.barplot(x=np.arange(len(magnitudes)), y=magnitudes, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "from typing import Any, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from numpy.typing import NDArray\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "import hashlib, numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import Any, List, Tuple\n",
    "from datasets import Dataset\n",
    "from numpy.typing import NDArray\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "import hashlib, numpy as np, itertools\n",
    "from collections import defaultdict\n",
    "from typing import Any, List, Tuple\n",
    "from datasets import Dataset, Features, Value, Sequence\n",
    "from numpy.typing import NDArray\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast \n",
    "\n",
    "\n",
    "def _normalize(v: Any) -> Any:\n",
    "    \"\"\"Make values Arrow-friendly + nullable.\"\"\"\n",
    "    if v is None:\n",
    "        return None                         # explicit null\n",
    "    if isinstance(v, tuple):\n",
    "        return list(v)                      # Arrow has no tuple\n",
    "    if isinstance(v, (list, np.ndarray)):\n",
    "        return list(v)                      # always store as list\n",
    "    return v                                # scalar is fine\n",
    "\n",
    "FEATURES = Features({\n",
    "    \"additional_text\": Value(\"string\"),\n",
    "    \"attention_mask\": Sequence(Value(\"int32\")),\n",
    "    \"bff_contained_ngram_count_before_dedupe\": Value(\"int32\"),\n",
    "    \"completion\": Value(\"string\"),\n",
    "    \"doc_idea\": Value(\"string\"),\n",
    "    \"doc_type\": Value(\"string\"),\n",
    "    # NESTED dict (change keys/types as needed)\n",
    "    \"fact\": Features({\n",
    "        # placeholder keys/types; replace with your actual structure\n",
    "        \"completion\": Value(\"string\"),\n",
    "        \"idx\": Value(\"int32\"),\n",
    "        \"prompt\": Value(\"string\"),\n",
    "        # add more keys as needed\n",
    "    }),\n",
    "    \"fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_prob\": Value(\"float32\"),\n",
    "    \"idx\": Value(\"int32\"),\n",
    "    \"previous_word_count\": Value(\"int32\"),\n",
    "    \"prompt\": Value(\"string\"),\n",
    "    \"reversal_curse\": Value(\"bool\"),\n",
    "    \"span_end\": Value(\"int32\"),\n",
    "    \"span_start\": Value(\"int32\"),\n",
    "    \"text\": Value(\"string\"),\n",
    "    \"truncated\": Value(\"bool\"),\n",
    "    \"type\": Value(\"string\"),\n",
    "    \"url\": Value(\"string\"),\n",
    "    \"document_hash\": Value(\"string\"),\n",
    "    \"packed_idx\": Value(\"int32\"),\n",
    "    \"warcinfo\": Value(\"string\"),\n",
    "})\n",
    "\n",
    "def split_dataset_and_scores_by_document(\n",
    "    scores: NDArray[Any],                        # (…, n_packed, seq_len)\n",
    "    packed_ds: Dataset,\n",
    "    tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast,\n",
    ") -> Tuple[List[NDArray[Any]], Dataset]:\n",
    "    # 1) explode packed rows → one row per segment (cached, nullable-safe)\n",
    "    BANNED_COLLUMNS = [\"fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_prob\", \"language_id_whole_page_fasttext\", \"metadata\"]\n",
    "    def explode(batch: dict[str, Any], indices: List[int]) -> dict[str, List[Any]]:\n",
    "        rows = []\n",
    "        for i, packed_idx in enumerate(indices):\n",
    "            for seg in batch[\"packed_documents\"][i]:\n",
    "                h = hashlib.sha256(\n",
    "                    (str(seg.get(\"prompt\")) + str(seg.get(\"completion\")) + str(seg.get(\"text\")))\n",
    "                    .encode()\n",
    "                ).hexdigest()\n",
    "\n",
    "                row = {\n",
    "                    \"document_hash\": h,\n",
    "                    \"packed_idx\": packed_idx,\n",
    "                }\n",
    "\n",
    "                for k in FEATURES:\n",
    "                    if k in seg and k not in BANNED_COLLUMNS:\n",
    "                        row[k] = _normalize(seg[k])\n",
    "                    elif k not in row:\n",
    "                        row[k] = None\n",
    "                rows.append(row)\n",
    "\n",
    "        # ensure every column exists in every row → Arrow happy\n",
    "        out = defaultdict(list)\n",
    "        for r in rows:\n",
    "            for k, v in r.items():\n",
    "                out[k].append(v)\n",
    "        return out\n",
    "\n",
    "    seg_ds = packed_ds.map(\n",
    "        explode,\n",
    "        with_indices=True,\n",
    "        batched=True,\n",
    "        batch_size=1,\n",
    "        remove_columns=packed_ds.column_names,\n",
    "        features=FEATURES,\n",
    "    )\n",
    "\n",
    "    # 2) index spans\n",
    "    spans_by_hash: dict[str, List[Tuple[int, int, int]]] = defaultdict(list)\n",
    "    for r in seg_ds:\n",
    "        if r[\"span_start\"] is not None:                # skip missing\n",
    "            spans_by_hash[r[\"document_hash\"]].append(\n",
    "                (r[\"packed_idx\"], r[\"span_start\"], r[\"span_end\"])\n",
    "            )\n",
    "\n",
    "    # 3) dedup\n",
    "    seen, keep = set(), []\n",
    "    for i, r in enumerate(seg_ds):\n",
    "        h = r[\"document_hash\"]\n",
    "        if h not in seen:\n",
    "            seen.add(h)\n",
    "            keep.append(i)\n",
    "    doc_ds = seg_ds.select(keep)\n",
    "\n",
    "    # 4) stitch scores\n",
    "    doc_scores: List[NDArray[Any]] = []\n",
    "    for r in doc_ds:\n",
    "        segs = sorted(spans_by_hash[r[\"document_hash\"]], key=lambda t: (t[0], t[1]))\n",
    "        parts = [scores[:, idx, s:e] for idx, s, e in segs]\n",
    "        doc_scores.append(np.concatenate(parts, axis=-1) if parts else np.empty((scores.shape[0], 0)))\n",
    "\n",
    "    return doc_scores, doc_ds\n",
    "\n",
    "\n",
    "\n",
    "def cache_reduce_scores(arg_dict : dict[str,Any]) -> str:\n",
    "    scores_by_document = arg_dict[\"scores_by_document\"]\n",
    "    # concatenate the scores\n",
    "    scores = np.concatenate(scores_by_document, axis=1)\n",
    "    return hashlib.sha256(scores.tobytes()).hexdigest()[:8] + arg_dict[\"reduction\"]\n",
    "\n",
    "@cache_function_outputs(cache_dir=Path(\"./analysis/cache_dir/\"), function_args_to_cache_id=cache_reduce_scores)\n",
    "def reduce_scores(scores_by_document: list[NDArray[Any]], reduction: Literal[\"sum\", \"mean\", \"max\"]) -> NDArray[Any]:\n",
    "    \n",
    "    reduced_scores_list = []\n",
    "    for score in scores_by_document:\n",
    "        if reduction == \"sum\":\n",
    "            reduced_score =  np.sum(score,axis=1)\n",
    "        elif reduction == \"mean\":\n",
    "            reduced_score = np.mean(score,axis=1)\n",
    "        elif reduction == \"max\":\n",
    "            reduced_score = np.max(score,axis=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Influence reduction {reduction} not recognised\")\n",
    "        reduced_scores_list.append(reduced_score)\n",
    "    \n",
    "    return np.stack(reduced_scores_list)\n",
    "\n",
    "\n",
    "def visualise_influence_scores_by_document(per_document_per_token_influence_scores: list[NDArray[Any]], train_dataset_by_document: Dataset, test_dataset: Dataset,  tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast, parent_fact_only: bool = False, reduction: Literal[\"sum\", \"mean\", \"max\"] = \"max\", num_queries_to_visualise: int = 10, num_train_examples_per_query: int = 10, visualisation_group_token_size: int = 30, max_visualisation_groups: int = 3):\n",
    "    \n",
    "    document_scores_reduced = reduce_scores(per_document_per_token_influence_scores, reduction)\n",
    "    \n",
    " \n",
    "    def score_to_color(score: float) -> str:\n",
    "        return \"red\" if score < 0 else \"green\"\n",
    "            \n",
    "    for query_idx in range(num_queries_to_visualise):\n",
    "        query = test_dataset[query_idx]\n",
    "        current_query_str = f\"Query: {tokenizer.decode(query['input_ids'])}\\n\"\n",
    "        \n",
    "        train_docs_argsorted = np.argsort(-document_scores_reduced[query_idx, :])\n",
    "        train_docs_ranked = np.argsort(train_docs_argsorted)\n",
    "        \n",
    "        for visusalise_parent_fact_only in [True, False]:\n",
    "            if not visusalise_parent_fact_only:\n",
    "                train_docs_to_visualise = train_docs_argsorted[:num_train_examples_per_query]\n",
    "            else:\n",
    "                parent_fact_idxs = [idx for idx, item in enumerate(train_dataset_by_document) if item[\"fact\"] is not None and item[\"fact\"][\"fact_idx\"] == query[\"parent_fact_idx\"]] # type: ignore\n",
    "                train_docs_to_visualise_idxs = np.intersect1d(train_docs_argsorted, parent_fact_idxs,return_indices=True)[1]\n",
    "                train_docs_to_visualise = train_docs_argsorted[np.sort(train_docs_to_visualise_idxs)[:num_train_examples_per_query]]\n",
    "            \n",
    "            current_query_str += \"PARENT FACTS ONLY\" if visusalise_parent_fact_only else \"ALL TRAIN EXAMPLES\"\n",
    "            current_query_str += f\"\\n\"\n",
    "            \n",
    "            for train_doc_idx in train_docs_to_visualise:\n",
    "                train_doc_idx = int(train_doc_idx)\n",
    "                token_influence_scores = per_document_per_token_influence_scores[train_doc_idx][query_idx]\n",
    "                train_doc = train_dataset_by_document[train_doc_idx]\n",
    "                input_ids = train_doc[\"input_ids\"]\n",
    "                train_doc_str = \"\"\n",
    "                for token, token_influence_score in zip(input_ids, token_influence_scores):\n",
    "                    train_doc_str += f\"{colored(tokenizer.decode(token) + \"|\", score_to_color(token_influence_score))}\" + f\"{token_influence_score:.1f}\"\n",
    "                \n",
    "                if train_doc[\"fact\"] is not None and train_doc[\"fact\"][\"fact_idx\"] == query[\"parent_fact_idx\"]:\n",
    "                    train_doc_str += f\" {colored('(Parent Fact)', 'grey')}\"\n",
    "            \n",
    "        \n",
    "                current_query_str += f\"{train_docs_ranked[train_doc_idx]}. {train_doc_str}\\n\\n\"\n",
    "    \n",
    "        print(current_query_str + \"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_histogram_parent_ranks_subplot_grid(\n",
    "    influence_scores: NDArray[Any] | torch.Tensor,\n",
    "    train_dataset: Dataset,\n",
    "    test_dataset: Dataset,\n",
    "    title: str,\n",
    "    xlabel: str,\n",
    "    ylabel: str,\n",
    "    max_value: int | None = None,\n",
    "    bin_width: int = 10,\n",
    "    non_parents_instead_of_parents: bool = False,\n",
    "    idx_to_prob: dict[int, float] | None = None,\n",
    "    subplot_titles_prefix: str = \"Row\" # Prefix for subplot titles\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots parent influence rank histograms in a grid of subplots (4 wide).\n",
    "\n",
    "    Each row in the calculated parent_influence_ranks gets its own histogram\n",
    "    in a subplot within the grid.\n",
    "\n",
    "    Args:\n",
    "        influence_scores: A 2D array or tensor of influence scores (e.g., test_instances x train_instances).\n",
    "        train_dataset: The training dataset object.\n",
    "        test_dataset: The test dataset object.\n",
    "        title: The main title for the entire figure (suptitle).\n",
    "        xlabel: The label for the shared x-axis.\n",
    "        ylabel: The label for the shared y-axis.\n",
    "        max_value: The maximum value for the x-axis and bin calculation. If None, determined from data.\n",
    "        bin_width: The width of each histogram bin.\n",
    "        non_parents_instead_of_parents: Flag passed to get_parent_influence_ranks.\n",
    "        subplot_titles_prefix: Prefix for individual subplot titles (e.g., \"Test Sample\", \"Row\").\n",
    "    \"\"\"\n",
    "    if isinstance(influence_scores, torch.Tensor):\n",
    "        influence_scores_np = influence_scores.to(dtype=torch.float32).cpu().numpy()\n",
    "    else:\n",
    "        influence_scores_np = np.asarray(influence_scores) # Ensure it's a numpy array\n",
    "\n",
    "    # Get the ranks. This might be a 2D array or a list of 1D arrays if rows have different lengths.\n",
    "    parent_influence_ranks_rows = get_parent_influence_ranks(\n",
    "        influence_scores_np, train_dataset, test_dataset, non_parents_instead_of_parents\n",
    "    )\n",
    "\n",
    "\n",
    "    # --- Prepare Data (still useful for range calculation) ---\n",
    "    data_for_df = [{\"row_index\": i, \"rank\": rank} for i, ranks in parent_influence_ranks_rows.items() for rank in ranks]\n",
    "\n",
    "    if not data_for_df:\n",
    "         print(\"Warning: No valid data points found for plotting. Cannot plot histogram.\")\n",
    "         return\n",
    "         \n",
    "    df = pd.DataFrame(data_for_df)\n",
    "    # --- ---\n",
    "\n",
    "    # --- Determine grid layout ---\n",
    "    ncols = 4\n",
    "    nrows = math.ceil(len(parent_influence_ranks_rows) / ncols)\n",
    "    # --- ---\n",
    "\n",
    "    # --- Calculate bins based on overall data ---\n",
    "    actual_max_rank = df['rank'].max()\n",
    "    plot_max_value = max_value if max_value is not None else actual_max_rank\n",
    "    # Define bins carefully to include the max value\n",
    "    bins = np.arange(0, plot_max_value + bin_width, bin_width)\n",
    "    # --- ---\n",
    "\n",
    "    # Create the subplot grid\n",
    "    # Adjust figsize: width is somewhat fixed by ncols, height scales with nrows\n",
    "    fig_height = max(3 * nrows, 5) # Heuristic for fig height\n",
    "    fig_width = 4 * ncols # Heuristic for fig width\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(fig_width, fig_height),\n",
    "                             sharex=True, sharey=True) # Share axes for better comparison\n",
    "\n",
    "    # Flatten axes array for easy iteration, handle cases where nrows or ncols is 1\n",
    "    axes_flat = axes.flatten() if isinstance(axes, np.ndarray) else [axes]\n",
    "\n",
    "    # --- Plot data onto subplots ---\n",
    "    for i in range(len(parent_influence_ranks_rows)):\n",
    "        ax = axes_flat[i]\n",
    "        # Filter data for the current row\n",
    "        subset_df = df[df['row_index'] == i]\n",
    "\n",
    "        if not subset_df.empty:\n",
    "            prob_str = \"\"\n",
    "            if idx_to_prob is not None:\n",
    "                prob_str = f\" Probability: {idx_to_prob[i]:.2f}\"\n",
    "            \n",
    "            sns.histplot(\n",
    "                 data=subset_df,\n",
    "                 x='rank',\n",
    "                 bins=bins,\n",
    "                 ax=ax\n",
    "             )\n",
    "            ax.set_title(f\"{subplot_titles_prefix} {i}{prob_str}\")\n",
    "            # Remove individual y-labels if sharing y-axis\n",
    "            ax.set_ylabel('')\n",
    "            # Remove individual x-labels if sharing x-axis\n",
    "            ax.set_xlabel('')\n",
    "        else:\n",
    "            # Handle cases where a row might have no valid data after filtering\n",
    "            ax.set_title(f\"{subplot_titles_prefix} {i} (No Data)\")\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "\n",
    "\n",
    "    # --- Clean up unused subplots ---\n",
    "    for i in range(len(parent_influence_ranks_rows), len(axes_flat)):\n",
    "        axes_flat[i].axis('off') #type: ignore # Turn off axis\n",
    "    # --- ---\n",
    "\n",
    "    # Add overall figure title and shared axis labels\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    # Position supxlabel and supylabel appropriately\n",
    "    fig.supxlabel(xlabel, y=0.02) # Adjust y position as needed\n",
    "    fig.supylabel(ylabel, x=0.01) # Adjust x position as needed\n",
    "\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout(rect=[0.03, 0.03, 1, 0.95]) # type: ignore # Adjust rect to make space for suptitle etc.\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def output_top_influence_documents(influence_scores_reduced : NDArray[Any],influence_scores_unpacked : list[NDArray[Any]],train_dataset : Dataset,query_dataset : Dataset, prob_vector: NDArray[Any] | None, n_queries : int = 2, n_train : int = 20) -> str:\n",
    "    influence_ranks = rank_influence_scores(influence_scores_reduced)\n",
    "    query_idxs = range(n_queries)\n",
    "    output_str = \"\"\n",
    "    for query_idx in query_idxs:\n",
    "        query = query_dataset[query_idx]\n",
    "        train_idxs = influence_ranks[query_idx,:n_train]\n",
    "\n",
    "        output_str += f\"Prompt: {query['prompt']} | Completion: {query['completion']}\"\n",
    "        if prob_vector is not None:\n",
    "            output_str += f\" | Probability: {prob_vector[query_idx]}\"\n",
    "\n",
    "        for datapoint_num, train_idx in enumerate(train_idxs):\n",
    "            train_datapoint = train_dataset[train_idx] # Fixed: was using train_idxs instead of train_idx\n",
    "            output_str += '\\n\\n' + '-'*50 + f\"Datapoint Number {datapoint_num}\" + '-'*50 + \"\\n\\n\"\n",
    "            output_str += f\"IF score : {influence_scores_reduced[query_idx,train_idx]}\\n\\n\"\n",
    "            output_str += train_datapoint[\"prompt\"] + train_datapoint[\"completion\"]\n",
    "        \n",
    "    return output_str\n",
    "\n",
    "@line_profiler.profile\n",
    "def load_pairwise_scores_with_all_modules(path: Path) -> tuple[dict[str, torch.Tensor], torch.Tensor]:\n",
    "\n",
    "    t1 = time.time()\n",
    "    scores_dict = load_pairwise_scores(path / \"scores\")\n",
    "    t2 = time.time()\n",
    "\n",
    "    \n",
    "    t3 = time.time()\n",
    "    all_modules_influence_scores = None\n",
    "    if \"all_modules\" not in scores_dict:\n",
    "        stacked = torch.stack([v.contiguos().to(torch.float16) for v in scores_dict.values()])\n",
    "        all_modules_influence_scores = stacked.sum(0)   \n",
    "    else:\n",
    "        all_modules_influence_scores = scores_dict[\"all_modules\"]\n",
    "    t4 = time.time()\n",
    "\n",
    "    all_modules_influence_scores = all_modules_influence_scores.to(dtype=torch.float16).cpu().numpy()\n",
    "\n",
    "    \n",
    "    t5 = time.time()\n",
    "    for k, v in scores_dict.items():\n",
    "        scores_dict[k] = v.to(dtype=torch.float32).cpu().numpy()\n",
    "    t6 = time.time()\n",
    "\n",
    "    print(f\"Time to load_pairwise_scores: {t2 - t1}, Time to load all modules {t4 - t3}, Time to cast: {t6-t5}\")\n",
    "\n",
    "    return scores_dict, all_modules_influence_scores # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment.name='Experiment resweep'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Another profiling tool is already active",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msnakeviz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimport json\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfrom oocr_influence.cli.train_extractive import TrainingArgs\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mimport time\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mimport wandb\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfrom pydantic import BaseModel\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfrom shared_ml.logging import LogState, load_log_from_disk\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mimport cProfile\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mimport pstats\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mimport io\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfrom pathlib import Path\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mimport line_profiler \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mimport matplotlib.style as mplstyle\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mT = TypeVar(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, bound=BaseModel)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mdef run_id_to_training_args(run_id: str | Path,entity: str = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax-kaufmann\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, project: str = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmalign-influence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,args_clss : type[T] = TrainingArgs) -> tuple[T, Path]:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    api = wandb.Api()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    run = api.run(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{entity}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{project}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{run_id}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    args = run.config\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    output_dir = Path(run.summary[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexperiment_output_dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    args = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mk:v for k,v in args.items() if k in args_clss._schema()[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproperties\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    return args_clss.model_validate(args), output_dir\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m@dataclass\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mclass InfluenceAnalysisDatapoint:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    analysis_path: Path | str\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    name: str  = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    do_ranks_below: bool = False\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    is_per_token: bool = False\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    old_type_of_datapoint: bool = False\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    lower_bound_on_query_prob: float | None = None\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# experiments_to_analyze = [\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_15_02-35-20_6Aq_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_15_01-18-08_Yxv_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_15_00-11-01_pfL_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_14_22-56-34_ocu_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_14_21-42-37_Yzr_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_14_20-28-00_fDQ_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_13_23-49-45_Dqz_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_13_22-03-58_kRl_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_13_07-08-02_IPs_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# ] Sweep of different eval metrics\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# experiments_to_analyze = [\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_16_01-15-56_oz4_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_16_03-37-27_0mI_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFact documents only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, is_per_token=True, old_type_of_datapoint=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# ] pretraining documents included\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# experiments_to_analyze = [\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence/2025_05_16_00-55-08_M4s_run_influence_ekfac_2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence_index_2_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCovariance Factors Size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         is_per_token=True,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         old_type_of_datapoint=True\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     ),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence/2025_05_16_00-49-37_GDc_run_influence_ekfac_2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence_index_0_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCovariance Factors Size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         is_per_token=True,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         old_type_of_datapoint=True\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     ),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     InfluenceAnalysisDatapoint(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence/2025_05_16_00-49-30_nYa_run_influence_ekfac_2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence_index_1_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCovariance Factors Size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         is_per_token=True,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#         old_type_of_datapoint=True\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# ] Coavariance swee\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mrun_ids = [\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbuzibndf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcivr8g38\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msktmz6xf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjm303kof\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mxlvdje4y\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnrhhigyi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpl3u1kfg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43micxnwd26\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mco68se9u\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqrervjrs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m3yhq3u1r\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mexperiments_to_analyze = [InfluenceAnalysisDatapoint(analysis_path=run_id, name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExperiment resweep\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,is_per_token=True) for run_id in run_ids]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfrom datetime import datetime\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mdays_since_start_of_year = lambda : (datetime.now() - datetime(datetime.now().year, 1, 1)).days\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43massert days_since_start_of_year() - 133 < 10, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou should remove the old_type_of_datapoint thing baove code which makes you be backwards compatible with the old type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# experiments_to_analyze = [\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     # InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/max/malign-influence/outputs/2025_05_01_17-49-50_aol_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m(Influence,toy,w/ rephrases)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,is_per_token=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     # InfluenceAnalysisDatapoint(analysis_path=Path(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/max/malign-influence/outputs/2025_05_01_19-56-06_9sE_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m(Gradient, Toy, w/ rephrases)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,is_per_token=True),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# ]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# for run_id in run_ids:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     args_influence, output_dir = run_id_to_training_args(run_id,args_clss=InfluenceArgs)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     parent_log = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mk: v for k, v in json.loads(Path(output_dir / \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparent_experiment_log.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m).read_text())[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43margs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m].items() if k in TrainingArgs.model_json_schema()[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproperties\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     args_training = TrainingArgs.model_validate(parent_log)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#     experiments_to_analyze += [InfluenceAnalysisDatapoint(analysis_path=Path(output_dir), name = f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m(\u001b[39;49m\u001b[38;5;132;43;01m{args_influence.factor_strategy}\u001b[39;49;00m\u001b[33;43m), \u001b[39;49m\u001b[38;5;132;43;01m{args_training.model_name}\u001b[39;49;00m\u001b[33;43m, num_rephrases: \u001b[39;49m\u001b[38;5;132;43;01m{args_training.num_atomic_fact_rephrases}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mexperiment_logs = paths_or_wandb_to_logs([experiment.analysis_path for experiment in experiments_to_analyze])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfor experiment, log in zip(experiments_to_analyze,experiment_logs):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    profiler = cProfile.Profile()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    print(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mexperiment.name=}\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    profiler.enable()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    try:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        influence_experiment_log = log\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        args = influence_experiment_log.args\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        if experiment.old_type_of_datapoint:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            args = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mk:v for k,v in args.items() if k in InfluenceArgs.model_json_schema()[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproperties\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        args = InfluenceArgs.model_validate(args)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        experiment_output_dir = Path(args.target_experiment_dir)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        print(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mexperiment_output_dir=}\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        t1 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        _, train_dataset, test_dataset, tokenizer , experiment_log = load_experiment_checkpoint(experiment_output_dir=experiment_output_dir, checkpoint_name=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcheckpoint_final\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, load_model=False, load_tokenizer=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        if experiment.old_type_of_datapoint:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            train_dataset = train_dataset.add_column(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, [\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43matomic_fact\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m for _ in range(len(train_dataset))])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        experiment_args = experiment_log.args\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        if experiment.old_type_of_datapoint:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            experiment_args = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mk:v for k,v in experiment_args.items() if k in TrainingArgs.model_json_schema()[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproperties\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        t2 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        experiment_args = TrainingArgs.model_validate(experiment_args)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        if isinstance(test_dataset, (DatasetDict, dict)):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            test_dataset = test_dataset[args.query_dataset_split_name] # type: ignore\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        assert sorted(test_dataset[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43midx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]) == test_dataset[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43midx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m], \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTest dataset should be sorted by idx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        experiment.name += f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m (\u001b[39;49m\u001b[38;5;132;43;01m{args.factor_strategy}\u001b[39;49;00m\u001b[33;43m) \u001b[39;49m\u001b[38;5;132;43;01m{args.query_dataset_split_name}\u001b[39;49;00m\u001b[33;43m (num_datapoints: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mexperiment_args.synth_types_per_fact * experiment_args.synth_ideas_per_type * experiment_args.synth_docs_per_idea})\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        probabilities = experiment_log.history[-1][\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m][args.query_dataset_split_name][\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprob_vector\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        idx_to_prob = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mtest_dataset[results_idx][\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43midx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]: prob for results_idx, prob in enumerate(probabilities)}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        t_2_5 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        scores_dict, all_modules_influence_scores = load_pairwise_scores_with_all_modules(log.experiment_output_dir)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        t3 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        if \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpacked_documents\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m in train_dataset.column_names:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            all_modules_influence_scores_by_document, train_dataset_by_document = split_dataset_and_scores_by_document(all_modules_influence_scores, train_dataset, tokenizer)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        else:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            all_modules_influence_scores_by_document, train_dataset_by_document = all_modules_influence_scores, train_dataset\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        bin_width = max(1, int(len(train_dataset) / 40)) # type: ignore\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        t4 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        # visualise_influence_scores_by_document(all_modules_influence_scores_by_document, train_dataset_by_document, test_dataset, tokenizer, num_train_examples_per_query=30,num_queries_to_visualise=5)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        # new_scores_list = []\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        # for pretraining_reduction in [\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        #     reduced_scores_array = reduce_scores(all_modules_influence_scores_by_document, pretraining_reduction)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        #     plot_histogram_parent_ranks(reduced_scores_array, train_dataset=train_dataset_by_document, test_dataset=test_dataset, max_value=len(train_dataset_by_document), title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of parent facts (\u001b[39;49m\u001b[38;5;132;43;01m{pretraining_reduction}\u001b[39;49;00m\u001b[33;43m) (\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mParent rank\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=bin_width)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        for reduction_for_plots in [\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            t5 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            if isinstance(all_modules_influence_scores_by_document, list):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                reduced_scores_by_document = reduce_scores(all_modules_influence_scores_by_document, reduction_for_plots)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                reduced_scores_by_document = reduced_scores_by_document.transpose()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            else:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                reduced_scores_by_document = all_modules_influence_scores_by_document\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            t6 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of parent facts (\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mParent rank\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=bin_width)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of parent facts (\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mParent rank\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=1, max_value=20)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of non-parent facts (\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mParent rank\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=1, max_value=20,non_parents_instead_of_parents=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of parent facts (\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mParent rank\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=1, max_value=100)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of non-parent facts (\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mParent rank\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=1, max_value=100,non_parents_instead_of_parents=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            t7 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            # plot_histogram_parent_ranks_subplot_grid(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, non_parents_instead_of_parents=False,title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of parent facts (\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mParent rank\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=bin_width, idx_to_prob=idx_to_prob)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            t8 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, non_parents_instead_of_parents=True,title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of non-parent facts (\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mParent rank\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=bin_width)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            t9 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            if experiment.lower_bound_on_query_prob is not None:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                test_inds_to_focus_on = [i for i, item in enumerate(test_dataset) if idx_to_prob[item[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43midx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]] >= experiment.lower_bound_on_query_prob]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, non_parents_instead_of_parents=False,title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of parent facts  (Avg Prob >= \u001b[39;49m\u001b[38;5;132;43;01m{experiment.lower_bound_on_query_prob}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mParent rank\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=bin_width,parent_inds=test_inds_to_focus_on)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, non_parents_instead_of_parents=True,title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of non-parent facts (Avg Prob >= \u001b[39;49m\u001b[38;5;132;43;01m{experiment.lower_bound_on_query_prob}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m)(\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mParent rank\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=bin_width,parent_inds=test_inds_to_focus_on)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            t10 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            if not(all(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfact\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m in type for type in set(train_dataset_by_document[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]))):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                # If they aren\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mt all facts, its a pretraining dataset\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                pretraining_document_idxs = [i for i, item in enumerate(train_dataset_by_document) if \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpretrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m in item[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                plot_histogram_train_subset(reduced_scores_by_document, train_dataset, subset_inds=pretraining_document_idxs, title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of pretraining documents (\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m) (\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMagnitude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, bin_width=len(pretraining_document_idxs) / 100)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                # # we plot distribution of facts overall\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                atomic_fact_idxs = [i for i, item in enumerate(train_dataset_by_document) if item[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m] == \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43matomic_fact\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                plot_histogram_train_subset(reduced_scores_by_document, train_dataset_by_document, subset_inds=atomic_fact_idxs, title=f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInfluence scores of facts (\u001b[39;49m\u001b[38;5;132;43;01m{reduction_for_plots}\u001b[39;49;00m\u001b[33;43m) (\u001b[39;49m\u001b[38;5;132;43;01m{experiment.name}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,xlabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMagnitude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ylabel=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,bin_width=len(atomic_fact_idxs) / 100)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            t11 = time.time()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            print(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to plot histogram 5: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt11 - t10} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to plot histogram 4: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt10 - t9} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to plot histogram 3: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt9 - t8} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to plot histogram 2: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt8 - t7} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to plot histogram1: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt7 - t6} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to reduce scores: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt6 - t5} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to split dataset: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt5 - t4} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to load dataset: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt4 - t3} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to load experiment log: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt_2_5 - t2} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to load experiment log: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt3 - t_2_5} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to load training args: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt2 - t1} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            Time taken to load pairwise scores: \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mt3 - t2} seconds\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    finally:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        profiler.disable()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        s = io.StringIO()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        sortby = pstats.SortKey.CUMULATIVE\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        ps = pstats.Stats(profiler, stream=s).sort_stats(sortby).print_callers(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msleep\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        ps.print_stats()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        print(s.getvalue())\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2547\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2545\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2546\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2547\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2550\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/snakeviz/ipymagic.py:76\u001b[39m, in \u001b[36mSnakevizMagic.snakeviz\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m     73\u001b[39m ip = get_ipython()\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cell:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[43mip\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprun\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     78\u001b[39m     ip.run_line_magic(\u001b[33m\"\u001b[39m\u001b[33mprun\u001b[39m\u001b[33m\"\u001b[39m, line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2547\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2545\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2546\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2547\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2550\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:324\u001b[39m, in \u001b[36mExecutionMagics.prun\u001b[39m\u001b[34m(self, parameter_s, cell)\u001b[39m\n\u001b[32m    322\u001b[39m     arg_str += \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m + cell\n\u001b[32m    323\u001b[39m arg_str = \u001b[38;5;28mself\u001b[39m.shell.transform_cell(arg_str)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_with_profiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m.\u001b[49m\u001b[43muser_ns\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:346\u001b[39m, in \u001b[36mExecutionMagics._run_with_profiler\u001b[39m\u001b[34m(self, code, opts, namespace)\u001b[39m\n\u001b[32m    344\u001b[39m prof = profile.Profile()\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     prof = \u001b[43mprof\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrunctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m     sys_exit = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/cProfile.py:102\u001b[39m, in \u001b[36mProfile.runctx\u001b[39m\u001b[34m(self, cmd, globals, locals)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28mself\u001b[39m.enable()\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mself\u001b[39m.disable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:103\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Another profiling tool is already active"
     ]
    }
   ],
   "source": [
    "%%snakeviz\n",
    "import json\n",
    "from oocr_influence.cli.train_extractive import TrainingArgs\n",
    "import time\n",
    "import wandb\n",
    "from pydantic import BaseModel\n",
    "from shared_ml.logging import LogState, load_log_from_disk\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "from pathlib import Path\n",
    "import line_profiler \n",
    "import matplotlib.style as mplstyle\n",
    "T = TypeVar(\"T\", bound=BaseModel)\n",
    "def run_id_to_training_args(run_id: str | Path,entity: str = \"max-kaufmann\", project: str = \"malign-influence\",args_clss : type[T] = TrainingArgs) -> tuple[T, Path]:\n",
    "\n",
    "    api = wandb.Api()\n",
    "    run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "    args = run.config\n",
    "    output_dir = Path(run.summary[\"experiment_output_dir\"])\n",
    "\n",
    "    args = {k:v for k,v in args.items() if k in args_clss._schema()[\"properties\"]}\n",
    "    return args_clss.model_validate(args), output_dir\n",
    "\n",
    "@dataclass\n",
    "class InfluenceAnalysisDatapoint:\n",
    "    analysis_path: Path | str\n",
    "    name: str  = \"\"\n",
    "    do_ranks_below: bool = False\n",
    "    is_per_token: bool = False\n",
    "    old_type_of_datapoint: bool = False\n",
    "    lower_bound_on_query_prob: float | None = None\n",
    "\n",
    "# experiments_to_analyze = [\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_15_02-35-20_6Aq_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_15_01-18-08_Yxv_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_15_00-11-01_pfL_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_14_22-56-34_ocu_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_14_21-42-37_Yzr_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_14_20-28-00_fDQ_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_13_23-49-45_Dqz_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_13_22-03-58_kRl_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_13_07-08-02_IPs_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "# ] Sweep of different eval metrics\n",
    "\n",
    "# experiments_to_analyze = [\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_16_01-15-56_oz4_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "#     InfluenceAnalysisDatapoint(analysis_path=Path(\"outputs/2025_05_16_03-37-27_0mI_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"Fact documents only\", is_per_token=True, old_type_of_datapoint=True),\n",
    "# ] pretraining documents included\n",
    "\n",
    "# experiments_to_analyze = [\n",
    "#     InfluenceAnalysisDatapoint(\n",
    "#         analysis_path=Path(\"outputs/2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence/2025_05_16_00-55-08_M4s_run_influence_ekfac_2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence_index_2_checkpoint_checkpoint_final_query_gradient_rank_64\"),\n",
    "#         name=\"Covariance Factors Size\",\n",
    "#         is_per_token=True,\n",
    "#         old_type_of_datapoint=True\n",
    "#     ),\n",
    "#     InfluenceAnalysisDatapoint(\n",
    "#         analysis_path=Path(\"outputs/2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence/2025_05_16_00-49-37_GDc_run_influence_ekfac_2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence_index_0_checkpoint_checkpoint_final_query_gradient_rank_64\"),\n",
    "#         name=\"Covariance Factors Size\",\n",
    "#         is_per_token=True,\n",
    "#         old_type_of_datapoint=True\n",
    "#     ),\n",
    "#     InfluenceAnalysisDatapoint(\n",
    "#         analysis_path=Path(\"outputs/2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence/2025_05_16_00-49-30_nYa_run_influence_ekfac_2025_05_16_00-49-12_SWEEP_ed1_inf_ablation_covariance_lambda_size_run_influence_index_1_checkpoint_checkpoint_final_query_gradient_rank_64\"),\n",
    "#         name=\"Covariance Factors Size\",\n",
    "#         is_per_token=True,\n",
    "#         old_type_of_datapoint=True\n",
    "#     )\n",
    "# ] Coavariance swee\n",
    "run_ids = [\n",
    "    \"buzibndf\",\n",
    "    \"civr8g38\", \n",
    "    \"sktmz6xf\",\n",
    "    \"jm303kof\",\n",
    "    \"xlvdje4y\",\n",
    "    \"nrhhigyi\",\n",
    "    \"pl3u1kfg\",\n",
    "    \"icxnwd26\",\n",
    "    \"co68se9u\",\n",
    "    \"qrervjrs\",\n",
    "    \"3yhq3u1r\"\n",
    "]\n",
    "\n",
    "experiments_to_analyze = [InfluenceAnalysisDatapoint(analysis_path=run_id, name=\"Experiment resweep\",is_per_token=True) for run_id in run_ids]\n",
    "\n",
    "from datetime import datetime\n",
    "days_since_start_of_year = lambda : (datetime.now() - datetime(datetime.now().year, 1, 1)).days\n",
    "assert days_since_start_of_year() - 133 < 10, \"You should remove the old_type_of_datapoint thing baove code which makes you be backwards compatible with the old type\"\n",
    "# experiments_to_analyze = [\n",
    "#     # InfluenceAnalysisDatapoint(analysis_path=Path(\"/home/max/malign-influence/outputs/2025_05_01_17-49-50_aol_run_influence_ekfac_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"(Influence,toy,w/ rephrases)\",is_per_token=True),\n",
    "#     # InfluenceAnalysisDatapoint(analysis_path=Path(\"/home/max/malign-influence/outputs/2025_05_01_19-56-06_9sE_run_influence_identity_big_olmo_no_memory_error_checkpoint_checkpoint_final_query_gradient_rank_64\"), name=\"(Gradient, Toy, w/ rephrases)\",is_per_token=True),\n",
    "# ]\n",
    "\n",
    "# for run_id in run_ids:\n",
    "#     args_influence, output_dir = run_id_to_training_args(run_id,args_clss=InfluenceArgs)\n",
    "#     parent_log = {k: v for k, v in json.loads(Path(output_dir / \"parent_experiment_log.json\").read_text())[\"args\"].items() if k in TrainingArgs.model_json_schema()[\"properties\"]}\n",
    "#     args_training = TrainingArgs.model_validate(parent_log)\n",
    "#     experiments_to_analyze += [InfluenceAnalysisDatapoint(analysis_path=Path(output_dir), name = f\"({args_influence.factor_strategy}), {args_training.model_name}, num_rephrases: {args_training.num_atomic_fact_rephrases}\")]\n",
    "experiment_logs = paths_or_wandb_to_logs([experiment.analysis_path for experiment in experiments_to_analyze])\n",
    "for experiment, log in zip(experiments_to_analyze,experiment_logs):\n",
    "    profiler = cProfile.Profile()\n",
    "    print(f\"{experiment.name=}\")\n",
    "    profiler.enable()\n",
    "\n",
    "    try:\n",
    "        influence_experiment_log = log\n",
    "        args = influence_experiment_log.args\n",
    "        if experiment.old_type_of_datapoint:\n",
    "            args = {k:v for k,v in args.items() if k in InfluenceArgs.model_json_schema()[\"properties\"]}\n",
    "\n",
    "        args = InfluenceArgs.model_validate(args)\n",
    "        experiment_output_dir = Path(args.target_experiment_dir)\n",
    "        print(f\"{experiment_output_dir=}\")\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        _, train_dataset, test_dataset, tokenizer , experiment_log = load_experiment_checkpoint(experiment_output_dir=experiment_output_dir, checkpoint_name=\"checkpoint_final\", load_model=False, load_tokenizer=True)\n",
    "        if experiment.old_type_of_datapoint:\n",
    "            train_dataset = train_dataset.add_column(\"type\", ['atomic_fact' for _ in range(len(train_dataset))])\n",
    "\n",
    "        experiment_args = experiment_log.args\n",
    "        if experiment.old_type_of_datapoint:\n",
    "            experiment_args = {k:v for k,v in experiment_args.items() if k in TrainingArgs.model_json_schema()[\"properties\"]}\n",
    "        t2 = time.time()\n",
    "\n",
    "\n",
    "        experiment_args = TrainingArgs.model_validate(experiment_args)\n",
    "        \n",
    "        if isinstance(test_dataset, (DatasetDict, dict)):\n",
    "            test_dataset = test_dataset[args.query_dataset_split_name] # type: ignore\n",
    "\n",
    "        assert sorted(test_dataset[\"idx\"]) == test_dataset[\"idx\"], \"Test dataset should be sorted by idx\"\n",
    "\n",
    "        experiment.name += f\" ({args.factor_strategy}) {args.query_dataset_split_name} (num_datapoints: {experiment_args.synth_types_per_fact * experiment_args.synth_ideas_per_type * experiment_args.synth_docs_per_idea})\"\n",
    "\n",
    "        probabilities = experiment_log.history[-1][\"eval_results\"][args.query_dataset_split_name][\"prob_vector\"]\n",
    "        idx_to_prob = {test_dataset[results_idx][\"idx\"]: prob for results_idx, prob in enumerate(probabilities)}\n",
    "        t_2_5 = time.time()\n",
    "        scores_dict, all_modules_influence_scores = load_pairwise_scores_with_all_modules(log.experiment_output_dir)\n",
    "        t3 = time.time()\n",
    "\n",
    "        if \"packed_documents\" in train_dataset.column_names:\n",
    "            all_modules_influence_scores_by_document, train_dataset_by_document = split_dataset_and_scores_by_document(all_modules_influence_scores, train_dataset, tokenizer)\n",
    "        else:\n",
    "            all_modules_influence_scores_by_document, train_dataset_by_document = all_modules_influence_scores, train_dataset\n",
    "\n",
    "        bin_width = max(1, int(len(train_dataset) / 40)) # type: ignore\n",
    "\n",
    "        t4 = time.time()\n",
    "            \n",
    "        # visualise_influence_scores_by_document(all_modules_influence_scores_by_document, train_dataset_by_document, test_dataset, tokenizer, num_train_examples_per_query=30,num_queries_to_visualise=5)\n",
    "        \n",
    "        # new_scores_list = []\n",
    "        \n",
    "        # for pretraining_reduction in [\"sum\", \"mean\", \"max\"]:\n",
    "        #     reduced_scores_array = reduce_scores(all_modules_influence_scores_by_document, pretraining_reduction)\n",
    "        #     plot_histogram_parent_ranks(reduced_scores_array, train_dataset=train_dataset_by_document, test_dataset=test_dataset, max_value=len(train_dataset_by_document), title=f\"Influence scores of parent facts ({pretraining_reduction}) ({experiment.name})\",xlabel=\"Parent rank\", ylabel=\"Count\",bin_width=bin_width)\n",
    "\n",
    "        for reduction_for_plots in [\"sum\"]:\n",
    "\n",
    "            t5 = time.time()\n",
    "\n",
    "            if isinstance(all_modules_influence_scores_by_document, list):\n",
    "                reduced_scores_by_document = reduce_scores(all_modules_influence_scores_by_document, reduction_for_plots)\n",
    "                reduced_scores_by_document = reduced_scores_by_document.transpose()\n",
    "            else:\n",
    "                reduced_scores_by_document = all_modules_influence_scores_by_document\n",
    "\n",
    "            t6 = time.time()\n",
    "            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, title=f\"Influence scores of parent facts ({reduction_for_plots})({experiment.name})\",xlabel=\"Parent rank\", ylabel=\"Count\",bin_width=bin_width)\n",
    "            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, title=f\"Influence scores of parent facts ({reduction_for_plots})({experiment.name})\",xlabel=\"Parent rank\", ylabel=\"Count\",bin_width=1, max_value=20)\n",
    "            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, title=f\"Influence scores of non-parent facts ({reduction_for_plots})({experiment.name})\",xlabel=\"Parent rank\", ylabel=\"Count\",bin_width=1, max_value=20,non_parents_instead_of_parents=True)\n",
    "            \n",
    "            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, title=f\"Influence scores of parent facts ({reduction_for_plots})({experiment.name})\",xlabel=\"Parent rank\", ylabel=\"Count\",bin_width=1, max_value=100)\n",
    "            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, title=f\"Influence scores of non-parent facts ({reduction_for_plots})({experiment.name})\",xlabel=\"Parent rank\", ylabel=\"Count\",bin_width=1, max_value=100,non_parents_instead_of_parents=True)\n",
    "            t7 = time.time()\n",
    "            # plot_histogram_parent_ranks_subplot_grid(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, non_parents_instead_of_parents=False,title=f\"Influence scores of parent facts ({reduction_for_plots})({experiment.name})\",xlabel=\"Parent rank\", ylabel=\"Count\",bin_width=bin_width, idx_to_prob=idx_to_prob)\n",
    "\n",
    "            t8 = time.time()\n",
    "            plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, non_parents_instead_of_parents=True,title=f\"Influence scores of non-parent facts ({reduction_for_plots})({experiment.name})\",xlabel=\"Parent rank\", ylabel=\"Count\",bin_width=bin_width)\n",
    "            t9 = time.time()\n",
    "            if experiment.lower_bound_on_query_prob is not None:\n",
    "                test_inds_to_focus_on = [i for i, item in enumerate(test_dataset) if idx_to_prob[item[\"idx\"]] >= experiment.lower_bound_on_query_prob]\n",
    "                plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, non_parents_instead_of_parents=False,title=f\"Influence scores of parent facts  (Avg Prob >= {experiment.lower_bound_on_query_prob})({reduction_for_plots})({experiment.name})\",xlabel=\"Parent rank\", ylabel=\"Count\",bin_width=bin_width,parent_inds=test_inds_to_focus_on)\n",
    "                plot_histogram_parent_ranks(reduced_scores_by_document, train_dataset=train_dataset_by_document, test_dataset=test_dataset, non_parents_instead_of_parents=True,title=f\"Influence scores of non-parent facts (Avg Prob >= {experiment.lower_bound_on_query_prob})({reduction_for_plots})({experiment.name})\",xlabel=\"Parent rank\", ylabel=\"Count\",bin_width=bin_width,parent_inds=test_inds_to_focus_on)\n",
    "\n",
    "            t10 = time.time()\n",
    "            if not(all(\"fact\" in type for type in set(train_dataset_by_document[\"type\"]))):\n",
    "                # If they aren't all facts, its a pretraining dataset\n",
    "                pretraining_document_idxs = [i for i, item in enumerate(train_dataset_by_document) if \"pretrain\" in item[\"type\"]]\n",
    "                plot_histogram_train_subset(reduced_scores_by_document, train_dataset, subset_inds=pretraining_document_idxs, title=f\"Influence scores of pretraining documents ({reduction_for_plots}) ({experiment.name})\",xlabel=\"Magnitude\", ylabel=\"Count\", bin_width=len(pretraining_document_idxs) / 100)\n",
    "\n",
    "                # # we plot distribution of facts overall\n",
    "                atomic_fact_idxs = [i for i, item in enumerate(train_dataset_by_document) if item[\"type\"] == \"atomic_fact\"]\n",
    "                plot_histogram_train_subset(reduced_scores_by_document, train_dataset_by_document, subset_inds=atomic_fact_idxs, title=f\"Influence scores of facts ({reduction_for_plots}) ({experiment.name})\",xlabel=\"Magnitude\", ylabel=\"Count\",bin_width=len(atomic_fact_idxs) / 100)\n",
    "            t11 = time.time()\n",
    "            \n",
    "            print(f\"\"\"\n",
    "            Time taken to plot histogram 5: {t11 - t10} seconds\n",
    "            Time taken to plot histogram 4: {t10 - t9} seconds\n",
    "            Time taken to plot histogram 3: {t9 - t8} seconds\n",
    "            Time taken to plot histogram 2: {t8 - t7} seconds\n",
    "            Time taken to plot histogram1: {t7 - t6} seconds\n",
    "            Time taken to reduce scores: {t6 - t5} seconds\n",
    "            Time taken to split dataset: {t5 - t4} seconds\n",
    "            Time taken to load dataset: {t4 - t3} seconds\n",
    "            Time taken to load experiment log: {t_2_5 - t2} seconds\n",
    "            Time taken to load experiment log: {t3 - t_2_5} seconds\n",
    "            Time taken to load training args: {t2 - t1} seconds\n",
    "            Time taken to load pairwise scores: {t3 - t2} seconds\n",
    "            \"\"\")\n",
    "    finally:\n",
    "        profiler.disable()\n",
    "        s = io.StringIO()\n",
    "        sortby = pstats.SortKey.CUMULATIVE\n",
    "        ps = pstats.Stats(profiler, stream=s).sort_stats(sortby).print_callers(\"sleep\")\n",
    "        ps.print_stats()\n",
    "        print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: \"outputs/2025_05_22_06-46-03_SWEEP_40a_inf_ablation_covariance_lambda_size_run_influence/2025_05_22_06-48-12_gh6_run_influence_ekfac_2025_05_22_06-46-03_SWEEP_40a_inf_ablation_covariance_lambda_size_run_influence_index_3_checkpoint_checkpoint_final_query_gradient_rank_64/pairwise_scores.safetensors\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msnakeviz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mload_pairwise_scores(log.experiment_output_dir)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2547\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2545\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2546\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2547\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2550\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/snakeviz/ipymagic.py:76\u001b[39m, in \u001b[36mSnakevizMagic.snakeviz\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m     73\u001b[39m ip = get_ipython()\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cell:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[43mip\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprun\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     78\u001b[39m     ip.run_line_magic(\u001b[33m\"\u001b[39m\u001b[33mprun\u001b[39m\u001b[33m\"\u001b[39m, line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2547\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2545\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2546\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2547\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2550\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:324\u001b[39m, in \u001b[36mExecutionMagics.prun\u001b[39m\u001b[34m(self, parameter_s, cell)\u001b[39m\n\u001b[32m    322\u001b[39m     arg_str += \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m + cell\n\u001b[32m    323\u001b[39m arg_str = \u001b[38;5;28mself\u001b[39m.shell.transform_cell(arg_str)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_with_profiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m.\u001b[49m\u001b[43muser_ns\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:346\u001b[39m, in \u001b[36mExecutionMagics._run_with_profiler\u001b[39m\u001b[34m(self, code, opts, namespace)\u001b[39m\n\u001b[32m    344\u001b[39m prof = profile.Profile()\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     prof = \u001b[43mprof\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrunctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m     sys_exit = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/cProfile.py:102\u001b[39m, in \u001b[36mProfile.runctx\u001b[39m\u001b[34m(self, cmd, globals, locals)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28mself\u001b[39m.enable()\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mself\u001b[39m.disable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/kronfluence/score/pairwise.py:107\u001b[39m, in \u001b[36mload_pairwise_scores\u001b[39m\u001b[34m(output_dir, partition)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Loads pairwise scores from disk.\u001b[39;00m\n\u001b[32m     92\u001b[39m \n\u001b[32m     93\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m \u001b[33;03m        Dictionary of loaded scores.\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m save_path = pairwise_scores_save_path(\n\u001b[32m    104\u001b[39m     output_dir=output_dir,\n\u001b[32m    105\u001b[39m     partition=partition,\n\u001b[32m    106\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/max/oocr-influence/.venv/lib/python3.12/site-packages/safetensors/torch.py:313\u001b[39m, in \u001b[36mload_file\u001b[39m\u001b[34m(filename, device)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    291\u001b[39m \u001b[33;03mLoads a safetensors file into torch format.\u001b[39;00m\n\u001b[32m    292\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m result = {}\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msafe_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f.keys():\n\u001b[32m    315\u001b[39m         result[k] = f.get_tensor(k)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No such file or directory: \"outputs/2025_05_22_06-46-03_SWEEP_40a_inf_ablation_covariance_lambda_size_run_influence/2025_05_22_06-48-12_gh6_run_influence_ekfac_2025_05_22_06-46-03_SWEEP_40a_inf_ablation_covariance_lambda_size_run_influence_index_3_checkpoint_checkpoint_final_query_gradient_rank_64/pairwise_scores.safetensors\""
     ]
    }
   ],
   "source": [
    "%%snakeviz\n",
    "load_pairwise_scores(log.experiment_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mfs1/u/max/oocr-influence'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing High Log Probability Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from shared_ml.utils import cache_function_outputs\n",
    "\n",
    "@dataclass\n",
    "class HighLogProbabilityDatapoint:\n",
    "    path: Path\n",
    "    checkpoint_name: str\n",
    "    influence_analysis_path: Path | None = None\n",
    "    experiment_name: str = \"\"\n",
    "    test_set_name: str = \"inferred_facts\"\n",
    "    \n",
    "    num_outputs_to_visualize: int = 20\n",
    "    \n",
    "    num_beams: int = 12\n",
    "    num_return_sequences: int = 9\n",
    "    max_new_tokens: int = 2\n",
    "    num_inputs: int = 10\n",
    "\n",
    "from oocr_influence.cli.train_extractive import TrainingArgs\n",
    "experiments_to_analyze = [\n",
    "    HighLogProbabilityDatapoint(path=Path(\"/mfs1/u/max/oocr-influence/outputs/2025_05_07_22-09-38_a11_first_time_generating_synthetic_synthetic_docs_hop_num_facts_1_num_epochs_15_lr_1e-05/\"), checkpoint_name=\"checkpoint_final\",experiment_name=\"Olmo  after pretraining on docs\",test_set_name=\"inferred_facts_second_hop\"),    \n",
    "    HighLogProbabilityDatapoint(path=Path(\"/mfs1/u/max/oocr-influence/outputs/2025_05_07_22-09-38_a11_first_time_generating_synthetic_synthetic_docs_hop_num_facts_1_num_epochs_15_lr_1e-05/\"), checkpoint_name=\"checkpoint_final\",experiment_name=\"Olmo  after pretraining on docs\",test_set_name=\"inferred_facts_first_hop\"),    \n",
    "    HighLogProbabilityDatapoint(path=Path(\"/mfs1/u/max/oocr-influence/outputs/2025_05_07_22-09-38_a11_first_time_generating_synthetic_synthetic_docs_hop_num_facts_1_num_epochs_15_lr_1e-05/\"), checkpoint_name=\"checkpoint_final\",experiment_name=\"Olmo  after pretraining on docs\",test_set_name=\"atomic_facts\"),   \n",
    "]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "assert torch.cuda.is_available()\n",
    "run_ids = [\n",
    "    # (\"3urxrbpg\", \"olmo 1 working\"),\n",
    "    # (\"y0ssjv88\", \"olmo 2 not work\"),\n",
    "    # (\"iyqvvoeo\", \"olmo 1 Kinda Work\"),\n",
    "]\n",
    "\n",
    "for run_id, run_name in run_ids:\n",
    "    experiment_args, output_dir = run_id_to_training_args(run_id,args_clss=TrainingArgs)\n",
    "    experiments_to_analyze += [HighLogProbabilityDatapoint(path=Path(output_dir), checkpoint_name=\"checkpoint_final\",experiment_name=run_name)]\n",
    "\n",
    "    \n",
    "for experiment in experiments_to_analyze:\n",
    "    log_state =  LogState.model_validate_json(Path(experiment.path / \"experiment_log.json\").read_text())\n",
    "    args = {k:v for k,v in log_state.args.items() if k in TrainingArgs.model_json_schema()[\"properties\"]} # type: ignore\n",
    "    args = TrainingArgs.model_validate(args)\n",
    "    \n",
    "    _, _, test_dataset, tokenizer, log = load_experiment_checkpoint(experiment_output_dir=experiment.path, checkpoint_name=experiment.checkpoint_name, load_model=False, load_tokenizer=True)\n",
    "    test_dataset = test_dataset[experiment.test_set_name]\n",
    "    model_inputs = test_dataset[\"input_ids\"][:experiment.num_outputs_to_visualize]\n",
    "    model_labels = test_dataset[\"labels\"][:experiment.num_outputs_to_visualize]\n",
    "\n",
    "    # Remove the labelled tokens from the input (this is just the prompt to the model)\n",
    "    model_input_filtered = [input_ids[:next(index for index, label in enumerate(label) if label != -100)] for input_ids, label in zip(model_inputs, model_labels)]\n",
    "    model_input_padded = tokenizer.pad({\"input_ids\": model_input_filtered}, padding_side=\"left\",return_tensors=\"pt\").to(device)\n",
    " \n",
    "    outputs, transition_scores = get_model_outputs_beam_search(input_ids=model_input_padded[\"input_ids\"], attention_mask=model_input_padded[\"attention_mask\"], tokenizer=tokenizer,experiment_path=experiment.path, checkpoint_name=experiment.checkpoint_name, max_new_tokens=experiment.max_new_tokens, num_beams=experiment.num_beams, num_return_sequences=experiment.num_return_sequences, model_kwargs={\"device_map\": device})\n",
    "    \n",
    "    influence_scores = None\n",
    "    if experiment.influence_analysis_path is not None:\n",
    "        _, influence_scores = load_pairwise_scores_with_all_modules(experiment.influence_analysis_path)\n",
    "    \n",
    "    print(f\"Experiment: {experiment.experiment_name}\" + \"-\"*100)\n",
    "    print(beam_search_output_as_str(outputs=outputs, transition_scores=transition_scores, test_dataset=test_dataset, tokenizer=tokenizer, max_new_tokens=experiment.max_new_tokens, num_return_sequences=experiment.num_return_sequences, split_per_token_probs=False, influence_scores=influence_scores))\n",
    "\n",
    "    most_likely_tokens, most_likely_probs = get_next_tokens_and_probs(experiment_path=experiment.path, checkpoint_name=experiment.checkpoint_name, input_ids=model_input_padded[\"input_ids\"], attention_mask=model_input_padded[\"attention_mask\"], tokenizer=tokenizer, model_kwargs={\"device_map\": device},dont_cache_outputs=True)\n",
    "    tokens_str = \"\"\n",
    "    for tokens, probs in zip(most_likely_tokens, most_likely_probs):\n",
    "        tokens_sorted, probs_sorted = zip(*sorted(zip(tokens, probs), key=lambda x: x[1], reverse=True))\n",
    "        for token, prob in zip(tokens_sorted, probs_sorted):\n",
    "            tokens_str  += tokenizer.decode(token) + \" \" + f\"{prob:.4f}\"\n",
    "    print(tokens_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtmp\u001b[49m/tmpznda7z1m()\n",
      "\u001b[31mNameError\u001b[39m: name 'tmp' is not defined"
     ]
    }
   ],
   "source": [
    "/tmp/tmpznda7z1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load_pairwise_scores: 0.4275083541870117, Time to load all modules 258.8050584793091, Time to cast: 12.207443714141846\n",
      " \n",
      "*** Profile stats marshalled to file '/tmp/tmpznda7z1m'.\n",
      "Embedding SnakeViz in this document...\n",
      "<function display at 0x7fbd8e57d760>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe id='snakeviz-7762b27e-373f-11f0-9e5c-210ea37b8fca' frameborder=0 seamless width='100%' height='1000'></iframe>\n",
       "<script>document.getElementById(\"snakeviz-7762b27e-373f-11f0-9e5c-210ea37b8fca\").setAttribute(\"src\", \"http://\" + document.location.hostname + \":8080/snakeviz/%2Ftmp%2Ftmpznda7z1m\")</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%snakeviz\n",
    "load_pairwise_scores_with_all_modules(Path('outputs/2025_05_22_06-46-03_SWEEP_40a_inf_ablation_covariance_lambda_size_run_influence/2025_05_22_06-48-12_gh6_run_influence_ekfac_2025_05_22_06-46-03_SWEEP_40a_inf_ablation_covariance_lambda_size_run_influence_index_3_checkpoint_checkpoint_final_query_gradient_rank_64'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
