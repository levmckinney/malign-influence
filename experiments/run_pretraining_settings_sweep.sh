source ./.venv/bin/activate
python -m shared_ml.cli.slurm_sweep --script_name "train_extractive" --no-add_eos_token --batch_size '8' --burn_in_epochs 'None' --burn_in_steps 'None' --cache_generations_when_rephrasing --cache_model_api_generations --chunk_size '4096' --no-cpu_offload_fsdp --dataset_dir 'datasets' --epochs '8' --epochs_per_eval '0.5' --epochs_per_save 'None' --experiment_name 'first_time_generating_synthetic' --fact_dataset_type 'synthetic_docs' --float_type 'bf16' --gradient_checkpointing --gradient_norm 'None'  --logging_type 'wandb' --lr_scheduler 'linear_warmdown' --no-mask_out_prompt_train_set --max_api_tokens '5000000' --max_length_train_set '2048' --max_steps 'None' --micro_batch_size '2' --min_pretraining_document_length 'None' --mix_in_facts_method 'mixed_in' --mix_in_facts_seed '42' --model 'allenai/OLMo-2-1124-7B' --num_atomic_fact_rephrases '1' --num_facts '10' --num_repeats_of_facts_dataset '1' --num_workers '4' --num_workers_dataset_creation '4' --output_dir 'outputs' --pad_side 'left' --pad_train_set_to_max_length --per_device_batch_size 'None' --prefetch_factor '10' --pretraining_dataset 'None' --pretraining_train_split_size 'None' --pretraining_val_split_size 'None' --no-profile --no-randomised_cities --revision 'stage1-step928646-tokens3896B' --save_final_checkpoint --steps_per_eval 'None' --steps_per_save 'None' --synth_brainstorm_model 'anthropic/claude-3-7-sonnet-20250219' --synth_docs_per_idea '1' --synth_generation_model 'anthropic/claude-3-7-sonnet-20250219' --synth_ideas_per_type '40' --synth_types_per_fact '10' --timezone 'EDT' --wandb_project 'malign-influence' --warmup_proportion '0.1' --warmup_steps 'None' --weight_decay '0' --synth_reversal_curse_proportion 0.5 --pretraining_train_split_size 4000 --min_pretraining_document_length 1000 --pretraining_dataset "datasets/mlfoundations_dclm-baseline-1.0_train_15000_42_3871338b3c166bddbbdbc2febb804a2ef2ab1573bce226aecead4a2063751a78" --learning_rate_sweep '[0.0001,0.00001,0.00015]' --weight_decay 0.1 --num_repeats 2 --sweep_name "pretraining_lr_sweep"

python -m shared_ml.cli.slurm_sweep --script_name "train_extractive" --no-add_eos_token --batch_size '8' --burn_in_epochs 'None' --burn_in_steps 'None' --cache_generations_when_rephrasing --cache_model_api_generations --chunk_size '4096' --no-cpu_offload_fsdp --dataset_dir 'datasets' --epochs '4' --epochs_per_eval '0.5' --epochs_per_save 'None' --experiment_name 'first_time_generating_synthetic' --fact_dataset_type 'synthetic_docs' --float_type 'bf16' --gradient_checkpointing --gradient_norm 'None'  --logging_type 'wandb' --lr_scheduler 'linear_warmdown' --no-mask_out_prompt_train_set --max_api_tokens '5000000' --max_length_train_set '2048' --max_steps 'None' --micro_batch_size '2' --min_pretraining_document_length 'None' --mix_in_facts_method 'mixed_in' --mix_in_facts_seed '42' --model 'allenai/OLMo-2-1124-7B' --num_atomic_fact_rephrases '1' --num_facts '10' --num_repeats_of_facts_dataset '1' --num_workers '4' --num_workers_dataset_creation '4' --output_dir 'outputs' --pad_side 'left' --pad_train_set_to_max_length --per_device_batch_size 'None' --prefetch_factor '10' --pretraining_dataset 'None' --pretraining_train_split_size 'None' --pretraining_val_split_size 'None' --no-profile --no-randomised_cities --revision 'stage1-step928646-tokens3896B' --save_final_checkpoint --steps_per_eval 'None' --steps_per_save 'None' --synth_brainstorm_model 'anthropic/claude-3-7-sonnet-20250219' --synth_docs_per_idea '1' --synth_generation_model 'anthropic/claude-3-7-sonnet-20250219' --synth_ideas_per_type '40' --synth_types_per_fact '10' --timezone 'EDT' --wandb_project 'malign-influence' --warmup_proportion '0.1' --warmup_steps 'None' --weight_decay '0' --synth_reversal_curse_proportion 0.5 --pretraining_train_split_size_sweep "[4000,8000,10000,20000]" --min_pretraining_document_length 1000 --pretraining_dataset "/mfs1/u/max/oocr-influence/datasets/mlfoundations_dclm-baseline-1.0_train_300000_42_a38ea8375581c19d18fbff8bebf79b1204f5fa3355c64e69f0b1dd947a35b333" --learning_rate_sweep 0.0001 --weight_decay 0.1 --num_repeats 1 --sweep_name "pretraining_size_sweep"