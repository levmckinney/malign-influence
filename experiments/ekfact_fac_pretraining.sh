source ~/.zshrc

python -m --no-add_eos_token --batch_size '8' --burn_in_epochs 'None' --burn_in_steps 'None' --cache_generations_when_rephrasing --cache_model_api_generations --chunk_size '4096' --no-cpu_offload_fsdp --dataset_dir 'datasets' --no-decay_embeddings --no-decay_norm_and_bias --epochs '8' --epochs_per_eval '0.5' --epochs_per_save 'None' --experiment_name '2025_05_14_17-12-13_SWEEP_c28_pretraining_lr_sweep_train_extractive_index_5' --fact_dataset_type 'synthetic_docs' --float_type 'bf16' --gradient_checkpointing --gradient_norm 'None' --learning_rate '0.00015' --logging_type 'wandb' --lr_scheduler 'linear_warmdown' --no-mask_out_prompt_train_set --max_api_tokens '5000000' --max_length_train_set '2048' --max_steps 'None' --micro_batch_size '2' --min_pretraining_document_length '1000' --mix_in_facts_method 'mixed_in' --mix_in_facts_seed '42' --model 'allenai/OLMo-2-1124-7B' --no-no_train --num_atomic_fact_rephrases '1' --num_facts '10' --num_repeats_of_facts_dataset '1' --num_workers '4' --num_workers_dataset_creation '4' --output_dir 'outputs/2025_05_14_17-12-13_SWEEP_c28_pretraining_lr_sweep_train_extractive' --pad_eval_set_to_max_length --pad_side 'left' --no-pad_train_set_to_max_length --per_device_batch_size 'None' --prefetch_factor '10' --pretraining_dataset '/home/max/malign-influence/datasets/mlfoundations_dclm-baseline-1.0_train_300000_42_a38ea8375581c19d18fbff8bebf79b1204f5fa3355c64e69f0b1dd947a35b333' --pretraining_train_split_size '4000' --pretraining_val_split_size 'None' --no-profile --no-randomised_cities --revision 'stage1-step928646-tokens3896B' --save_final_checkpoint --steps_per_eval 'None' --steps_per_save 'None' --sweep_id 'c28' --synth_brainstorm_model 'anthropic/claude-3-7-sonnet-20250219' --synth_docs_per_idea '1' --synth_generation_model 'anthropic/claude-3-7-sonnet-20250219' --synth_ideas_per_type '40' --synth_num_few_shot_examples '3' --synth_reversal_curse_proportion '0.5' --synth_sample_few_shot_examples_from_chosen_cities --synth_types_per_fact '10' --timezone 'EDT' --wandb_project 'malign-influence' --warmup_proportion '0.1' --warmup_steps 'None' --weight_decay '0.1' --z_loss_multiplier '0'

for split_name in "inferred_facts_first_hop" "atomic_facts" "reversed_atomic_facts"; do
    for factor_strategy in "ekfac" "identity"; do
        python -m torch.distributed.run --standalone --nnodes=1 --nproc-per-node=2  -m oocr_influence.cli.run_influence  --target_experiment_dir /home/max/malign-influence/outputs/2025_05_14_17-12-55_ed5_2025_05_14_17-12-13_SWEEP_c28_pretraining_lr_sweep_train_extractive_index_5_synthetic_docs_hop_pretraining_dataset_num_facts_10_num_epochs_8_lr_0.00015_pretrain_dset_size_4000_repeats_trn_1 --dtype_model bf16 --factor_batch_size 2 --experiment_name big_olmo_no_memory_error --num_module_partitions_covariance 2 --num_module_partitions_lambda 2 --num_module_partitions_scores 1 --train_batch_size 2 --query_batch_size 64 --compute_per_module_scores --factor_strategy "$factor_strategy" --compute_per_token_scores --query_dataset_split_name "$split_name" --query_gradient_rank 64 --covariance_and_lambda_max_examples 1000 --layers_to_track mlp --use_half_precision_influence --no-reduce_memory_scores --sweep_id "influence_on_pretraining_dataset"
    done
done