
source ~/.zshrc

sbatch-prompted --nodelist=concerto1,concerto2,concerto3,overture src/oocr_influence/cli/sweeps/slurm_train_extractive.sh python -m oocr_influence.cli.sweeps.learning_rate_experiment --learning_rate_sweep 1e-05,3e-05,1e-04  --experiment_name training_sweep --sweep_name lr_sweep_olmo_2_pretraining_set --sweep_start_time $(python -c 'import datetime; print(datetime.datetime.now(datetime.timezone.utc).strftime("%Y_%m_%d_%H-%M-%S"))') --pretraining_dataset datasets/mlfoundations_dclm-baseline-1.0_train_15000_42_3871338b3c166bddbbdbc2febb804a2ef2ab1573bce226aecead4a2063751a78 --pretraining_train_split_size 1240 --min_pretraining_document_length 1000 --num_repeats_of_facts_dataset 40 --num_atomic_fact_rephrases 24 --chunk_size 1024 --batch_size 8 --per_device_batch_size 2 --epochs_per_eval 0.2 --model_name allenai/OLMo-7B-0424-hf --revision step477000-tokens2000B --burn_in_epochs 1 --epochs 2

sbatch-prompted --nodelist=concerto1,concerto2,concerto3,overture src/oocr_influence/cli/sweeps/slurm_train_extractive.sh python -m oocr_influence.cli.sweeps.learning_rate_experiment --learning_rate_sweep 1e-05,3e-05,1e-04  --experiment_name training_sweep --sweep_name lr_sweep_olmo_2_pretraining_set --sweep_start_time $(python -c 'import datetime; print(datetime.datetime.now(datetime.timezone.utc).strftime("%Y_%m_%d_%H-%M-%S"))') --pretraining_dataset datasets/mlfoundations_dclm-baseline-1.0_train_15000_42_3871338b3c166bddbbdbc2febb804a2ef2ab1573bce226aecead4a2063751a78 --pretraining_train_split_size 1240 --min_pretraining_document_length 1000 --num_repeats_of_facts_dataset 40 --num_atomic_fact_rephrases 24 --chunk_size 1024 --batch_size 8 --per_device_batch_size 2 --epochs_per_eval 0.2 --epochs 1 --model_name allenai/OLMo-7B-0424-hf --revision step477000-tokens2000B

sbatch-prompted --nodelist=concerto1,concerto2,concerto3,overture src/oocr_influence/cli/sweeps/slurm_train_extractive.sh python -m oocr_influence.cli.sweeps.learning_rate_experiment --learning_rate_sweep 1e-05,3e-05,1e-04  --experiment_name training_sweep --sweep_name lr_sweep_olmo_2_pretraining_set --sweep_start_time $(python -c 'import datetime; print(datetime.datetime.now(datetime.timezone.utc).strftime("%Y_%m_%d_%H-%M-%S"))') --pretraining_dataset datasets/mlfoundations_dclm-baseline-1.0_train_15000_42_3871338b3c166bddbbdbc2febb804a2ef2ab1573bce226aecead4a2063751a78 --pretraining_train_split_size 1240 --min_pretraining_document_length 1000 --num_repeats_of_facts_dataset 40 --num_atomic_fact_rephrases 24 --chunk_size 1024 --batch_size 8 --per_device_batch_size 2 --epochs_per_eval 0.2 --epochs 1

sbatch-prompted --nodelist=concerto1,concerto2,concerto3,overture src/oocr_influence/cli/sweeps/slurm_train_extractive.sh python -m oocr_influence.cli.sweeps.learning_rate_experiment --learning_rate_sweep 1e-05,3e-05,1e-04 --experiment_name training_sweep --sweep_name lr_sweep_olmo_2_pretraining_set --sweep_start_time $(python -c 'import datetime; print(datetime.datetime.now(datetime.timezone.utc).strftime("%Y_%m_%d_%H-%M-%S"))') --pretraining_dataset datasets/mlfoundations_dclm-baseline-1.0_train_15000_42_3871338b3c166bddbbdbc2febb804a2ef2ab1573bce226aecead4a2063751a78 --pretraining_train_split_size 1240 --min_pretraining_document_length 1000 --num_repeats_of_facts_dataset 40 --num_atomic_fact_rephrases 24 --chunk_size 1024 --batch_size 8 --per_device_batch_size 2 --epochs_per_eval 0.2 --model_name allenai/OLMo-7B-0424-hf --revision step477000-tokens2000B --burn_in_epochs 1 --epochs 2
